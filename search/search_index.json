{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Dvc Task API Reference","title":"Welcome to Dvc Task"},{"location":"#welcome-to-dvc-task","text":"API Reference","title":"Welcome to Dvc Task"},{"location":"reference/dvc_task/","text":"DVC Task.","title":"Dvc task"},{"location":"reference/dvc_task/exceptions/","text":"Exception classes. DvcTaskError Bases: Exception Base DVC Task exception. Source code in dvc_task/exceptions.py 4 5 class DvcTaskError ( Exception ): \"\"\"Base DVC Task exception.\"\"\"","title":"Exceptions"},{"location":"reference/dvc_task/exceptions/#dvc_task.exceptions.DvcTaskError","text":"Bases: Exception Base DVC Task exception. Source code in dvc_task/exceptions.py 4 5 class DvcTaskError ( Exception ): \"\"\"Base DVC Task exception.\"\"\"","title":"DvcTaskError"},{"location":"reference/dvc_task/utils/","text":"General utilities. makedirs ( path , exist_ok = False , mode = None ) Make the specified directory and any parent directories. Source code in dvc_task/utils.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def makedirs ( path : str , exist_ok : bool = False , mode : Optional [ int ] = None ): \"\"\"Make the specified directory and any parent directories.\"\"\" if mode is None : os . makedirs ( path , exist_ok = exist_ok ) return # Modified version of os.makedirs() with support for extended mode # (e.g. S_ISGID) head , tail = os . path . split ( path ) if not tail : head , tail = os . path . split ( head ) if head and tail and not os . path . exists ( head ): try : makedirs ( head , exist_ok = exist_ok , mode = mode ) except FileExistsError : # Defeats race condition when another thread created the path pass cdir = os . curdir if tail == cdir : # foo/newdir/. exists if foo/newdir exists return try : os . mkdir ( path , mode ) except OSError : # Cannot rely on checking for EEXIST, since the operating system # could give priority to other errors like EACCES or EROFS if not exist_ok or not os . path . isdir ( path ): raise try : os . chmod ( path , mode ) except OSError : logger . debug ( \"failed to chmod ' %o ' ' %s '\" , mode , path , exc_info = True ) remove ( path ) Remove the specified path. Source code in dvc_task/utils.py 35 36 37 38 39 40 41 42 43 44 45 def remove ( path : str ): \"\"\"Remove the specified path.\"\"\" logger . debug ( \"Removing ' %s '\" , path ) try : if os . path . isdir ( path ): shutil . rmtree ( path , onerror = _chmod ) else : _unlink ( path , _chmod ) except OSError as exc : if exc . errno != errno . ENOENT : raise unc_path ( path ) Return UNC formatted path. Returns the unmodified path on posix platforms. Source code in dvc_task/utils.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def unc_path ( path : str ) -> str : \"\"\"Return UNC formatted path. Returns the unmodified path on posix platforms. \"\"\" # Celery/Kombu URLs only take absolute filesystem paths # (UNC paths on windows) path = os . path . abspath ( path ) if os . name != \"nt\" : return path drive , tail = os . path . splitdrive ( path ) if drive . endswith ( \":\" ): return f \" \\\\\\\\ ? \\\\ { drive }{ tail } \" return f \" { drive }{ tail } \"","title":"Utils"},{"location":"reference/dvc_task/utils/#dvc_task.utils.makedirs","text":"Make the specified directory and any parent directories. Source code in dvc_task/utils.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def makedirs ( path : str , exist_ok : bool = False , mode : Optional [ int ] = None ): \"\"\"Make the specified directory and any parent directories.\"\"\" if mode is None : os . makedirs ( path , exist_ok = exist_ok ) return # Modified version of os.makedirs() with support for extended mode # (e.g. S_ISGID) head , tail = os . path . split ( path ) if not tail : head , tail = os . path . split ( head ) if head and tail and not os . path . exists ( head ): try : makedirs ( head , exist_ok = exist_ok , mode = mode ) except FileExistsError : # Defeats race condition when another thread created the path pass cdir = os . curdir if tail == cdir : # foo/newdir/. exists if foo/newdir exists return try : os . mkdir ( path , mode ) except OSError : # Cannot rely on checking for EEXIST, since the operating system # could give priority to other errors like EACCES or EROFS if not exist_ok or not os . path . isdir ( path ): raise try : os . chmod ( path , mode ) except OSError : logger . debug ( \"failed to chmod ' %o ' ' %s '\" , mode , path , exc_info = True )","title":"makedirs()"},{"location":"reference/dvc_task/utils/#dvc_task.utils.remove","text":"Remove the specified path. Source code in dvc_task/utils.py 35 36 37 38 39 40 41 42 43 44 45 def remove ( path : str ): \"\"\"Remove the specified path.\"\"\" logger . debug ( \"Removing ' %s '\" , path ) try : if os . path . isdir ( path ): shutil . rmtree ( path , onerror = _chmod ) else : _unlink ( path , _chmod ) except OSError as exc : if exc . errno != errno . ENOENT : raise","title":"remove()"},{"location":"reference/dvc_task/utils/#dvc_task.utils.unc_path","text":"Return UNC formatted path. Returns the unmodified path on posix platforms. Source code in dvc_task/utils.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def unc_path ( path : str ) -> str : \"\"\"Return UNC formatted path. Returns the unmodified path on posix platforms. \"\"\" # Celery/Kombu URLs only take absolute filesystem paths # (UNC paths on windows) path = os . path . abspath ( path ) if os . name != \"nt\" : return path drive , tail = os . path . splitdrive ( path ) if drive . endswith ( \":\" ): return f \" \\\\\\\\ ? \\\\ { drive }{ tail } \" return f \" { drive }{ tail } \"","title":"unc_path()"},{"location":"reference/dvc_task/app/","text":"DVC Task app factories. FSApp Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in dvc_task/app/filesystem.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def _iter_folder ( self , path_name : str , path_cache : Dict [ str , str ], queue : Optional [ str ] = None , ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks inside a folder Arguments: path_name: the folder to iterate path_cache: cache of message path. queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : folder = getattr ( channel , path_name ) for filename in sorted ( os . listdir ( folder )): path = os . path . join ( folder , filename ) try : with open ( path , \"rb\" ) as fobj : lock ( fobj , LOCK_SH ) try : payload = fobj . read () finally : unlock ( fobj ) except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue if not payload : continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue , ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue , ) @staticmethod def _delete_msg ( delivery_tag : str , msg_collection : Iterable [ Message ], path_cache : Dict [ str , str ], ): \"\"\"delete the specified message. Arguments: delivery_tag: delivery tag of the message to be deleted. msg_collection: where to found this message. path_cache: cache of message path. Raises: ValueError: Invalid delivery_tag \"\"\" path = path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del path_cache [ delivery_tag ] return for msg in msg_collection : if msg . delivery_tag == delivery_tag : remove ( path_cache [ delivery_tag ]) del path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache ) def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) __init__ ( args , wdir = None , mkdir = False , task_serializer = 'json' , result_serializer = 'json' , kwargs ) Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in dvc_task/app/filesystem.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} iter_processed ( queue = None ) Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 162 163 164 165 166 167 168 169 170 171 172 173 174 def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue , ) iter_queued ( queue = None ) Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 148 149 150 151 152 153 154 155 156 157 158 159 160 def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue , ) purge ( delivery_tag ) Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 216 217 218 219 220 221 222 223 224 225 226 227 def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) reject ( delivery_tag ) Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 205 206 207 208 209 210 211 212 213 214 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache )","title":"App"},{"location":"reference/dvc_task/app/#dvc_task.app.FSApp","text":"Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in dvc_task/app/filesystem.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def _iter_folder ( self , path_name : str , path_cache : Dict [ str , str ], queue : Optional [ str ] = None , ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks inside a folder Arguments: path_name: the folder to iterate path_cache: cache of message path. queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : folder = getattr ( channel , path_name ) for filename in sorted ( os . listdir ( folder )): path = os . path . join ( folder , filename ) try : with open ( path , \"rb\" ) as fobj : lock ( fobj , LOCK_SH ) try : payload = fobj . read () finally : unlock ( fobj ) except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue if not payload : continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue , ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue , ) @staticmethod def _delete_msg ( delivery_tag : str , msg_collection : Iterable [ Message ], path_cache : Dict [ str , str ], ): \"\"\"delete the specified message. Arguments: delivery_tag: delivery tag of the message to be deleted. msg_collection: where to found this message. path_cache: cache of message path. Raises: ValueError: Invalid delivery_tag \"\"\" path = path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del path_cache [ delivery_tag ] return for msg in msg_collection : if msg . delivery_tag == delivery_tag : remove ( path_cache [ delivery_tag ]) del path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache ) def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache )","title":"FSApp"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.__init__","text":"Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in dvc_task/app/filesystem.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {}","title":"__init__()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.iter_processed","text":"Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 162 163 164 165 166 167 168 169 170 171 172 173 174 def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue , )","title":"iter_processed()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.iter_queued","text":"Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 148 149 150 151 152 153 154 155 156 157 158 159 160 def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue , )","title":"iter_queued()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.purge","text":"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 216 217 218 219 220 221 222 223 224 225 226 227 def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache )","title":"purge()"},{"location":"reference/dvc_task/app/#dvc_task.app.filesystem.FSApp.reject","text":"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 205 206 207 208 209 210 211 212 213 214 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache )","title":"reject()"},{"location":"reference/dvc_task/app/filesystem/","text":"(Local) filesystem based Celery application. FSApp Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in dvc_task/app/filesystem.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def _iter_folder ( self , path_name : str , path_cache : Dict [ str , str ], queue : Optional [ str ] = None , ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks inside a folder Arguments: path_name: the folder to iterate path_cache: cache of message path. queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : folder = getattr ( channel , path_name ) for filename in sorted ( os . listdir ( folder )): path = os . path . join ( folder , filename ) try : with open ( path , \"rb\" ) as fobj : lock ( fobj , LOCK_SH ) try : payload = fobj . read () finally : unlock ( fobj ) except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue if not payload : continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue , ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue , ) @staticmethod def _delete_msg ( delivery_tag : str , msg_collection : Iterable [ Message ], path_cache : Dict [ str , str ], ): \"\"\"delete the specified message. Arguments: delivery_tag: delivery tag of the message to be deleted. msg_collection: where to found this message. path_cache: cache of message path. Raises: ValueError: Invalid delivery_tag \"\"\" path = path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del path_cache [ delivery_tag ] return for msg in msg_collection : if msg . delivery_tag == delivery_tag : remove ( path_cache [ delivery_tag ]) del path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache ) def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) __init__ ( args , wdir = None , mkdir = False , task_serializer = 'json' , result_serializer = 'json' , kwargs ) Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in dvc_task/app/filesystem.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} iter_processed ( queue = None ) Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 162 163 164 165 166 167 168 169 170 171 172 173 174 def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue , ) iter_queued ( queue = None ) Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 148 149 150 151 152 153 154 155 156 157 158 159 160 def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue , ) purge ( delivery_tag ) Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 216 217 218 219 220 221 222 223 224 225 226 227 def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache ) reject ( delivery_tag ) Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 205 206 207 208 209 210 211 212 213 214 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache )","title":"Filesystem"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp","text":"Bases: Celery Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend Source code in dvc_task/app/filesystem.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 class FSApp ( Celery ): \"\"\"Local filesystem-based Celery application. Uses Kombu filesystem:// broker and results backend \"\"\" def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {} def __reduce_keys__ ( self ) -> Dict [ str , Any ]: keys = super () . __reduce_keys__ () # type: ignore[misc] keys . update ({ \"wdir\" : self . wdir }) return keys def _iter_folder ( self , path_name : str , path_cache : Dict [ str , str ], queue : Optional [ str ] = None , ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks inside a folder Arguments: path_name: the folder to iterate path_cache: cache of message path. queue: Optional name of queue. \"\"\" queue = queue or self . conf . task_default_queue with self . connection_for_read () as conn : # type: ignore[attr-defined] with conn . channel () as channel : folder = getattr ( channel , path_name ) for filename in sorted ( os . listdir ( folder )): path = os . path . join ( folder , filename ) try : with open ( path , \"rb\" ) as fobj : lock ( fobj , LOCK_SH ) try : payload = fobj . read () finally : unlock ( fobj ) except FileNotFoundError : # Messages returned by `listdir` call may have been # acknowledged and moved to `processed_folder` by the # time we try to read them here continue if not payload : continue msg = channel . Message ( loads ( bytes_to_str ( payload )), channel = channel ) path_cache [ msg . delivery_tag ] = path delivery_info = msg . properties . get ( \"delivery_info\" , {}) if delivery_info . get ( \"routing_key\" ) == queue : yield msg def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue , ) def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue , ) @staticmethod def _delete_msg ( delivery_tag : str , msg_collection : Iterable [ Message ], path_cache : Dict [ str , str ], ): \"\"\"delete the specified message. Arguments: delivery_tag: delivery tag of the message to be deleted. msg_collection: where to found this message. path_cache: cache of message path. Raises: ValueError: Invalid delivery_tag \"\"\" path = path_cache . get ( delivery_tag ) if path and os . path . exists ( path ): remove ( path ) del path_cache [ delivery_tag ] return for msg in msg_collection : if msg . delivery_tag == delivery_tag : remove ( path_cache [ delivery_tag ]) del path_cache [ delivery_tag ] return raise ValueError ( f \"Message ' { delivery_tag } ' not found\" ) def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache ) def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache )","title":"FSApp"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.__init__","text":"Construct an FSApp. Parameters: Name Type Description Default wdir Optional [ str ] App broker/results directory. Defaults to current working directory. None mkdir bool Create broker/results subdirectories if they do not already exist. False task_serializer str Default task serializer. 'json' result_serializer str Default result serializer. 'json' Additional arguments will be passed into the Celery constructor. Source code in dvc_task/app/filesystem.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def __init__ ( self , * args , wdir : Optional [ str ] = None , mkdir : bool = False , task_serializer : str = \"json\" , result_serializer : str = \"json\" , ** kwargs : Any , ): \"\"\"Construct an FSApp. Arguments: wdir: App broker/results directory. Defaults to current working directory. mkdir: Create broker/results subdirectories if they do not already exist. task_serializer: Default task serializer. result_serializer: Default result serializer. Additional arguments will be passed into the Celery constructor. \"\"\" super () . __init__ ( * args , ** kwargs ) self . wdir = wdir or os . getcwd () self . conf . update ( _get_fs_config ( self . wdir , mkdir = mkdir , task_serializer = task_serializer , result_serializer = result_serializer , ) ) logger . debug ( \"Initialized filesystem:// app in ' %s '\" , wdir ) self . _processed_msg_path_cache : Dict [ str , str ] = {} self . _queued_msg_path_cache : Dict [ str , str ] = {}","title":"__init__()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.iter_processed","text":"Iterate over tasks which have been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 162 163 164 165 166 167 168 169 170 171 172 173 174 def iter_processed ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over tasks which have been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"processed_folder\" , self . _processed_msg_path_cache , queue , )","title":"iter_processed()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.iter_queued","text":"Iterate over queued tasks which have not been taken by a worker. Parameters: Name Type Description Default queue Optional [ str ] Optional name of queue. None Source code in dvc_task/app/filesystem.py 148 149 150 151 152 153 154 155 156 157 158 159 160 def iter_queued ( self , queue : Optional [ str ] = None ) -> Generator [ Message , None , None ]: \"\"\"Iterate over queued tasks which have not been taken by a worker. Arguments: queue: Optional name of queue. \"\"\" yield from self . _iter_folder ( \"data_folder_in\" , self . _queued_msg_path_cache , queue , )","title":"iter_queued()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.purge","text":"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 216 217 218 219 220 221 222 223 224 225 226 227 def purge ( self , delivery_tag : str ): \"\"\"Purge the specified processed message. Allows the caller to purge completed FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_processed (), self . _processed_msg_path_cache )","title":"purge()"},{"location":"reference/dvc_task/app/filesystem/#dvc_task.app.filesystem.FSApp.reject","text":"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: Type Description ValueError Invalid delivery_tag Source code in dvc_task/app/filesystem.py 205 206 207 208 209 210 211 212 213 214 def reject ( self , delivery_tag : str ): \"\"\"Reject the specified message. Allows the caller to reject FS broker messages without establishing a full Kombu consumer. Requeue is not supported. Raises: ValueError: Invalid delivery_tag \"\"\" self . _delete_msg ( delivery_tag , self . iter_queued (), self . _queued_msg_path_cache )","title":"reject()"},{"location":"reference/dvc_task/contrib/","text":"","title":"Contrib"},{"location":"reference/dvc_task/contrib/kombu_filesystem/","text":"Kombu filesystem transport module. Contains classes which need to be backported in kombu <5.3.0 via monkeypatch. FilesystemChannel Bases: virtual . Channel Filesystem Channel. Source code in dvc_task/contrib/kombu_filesystem.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 class FilesystemChannel ( virtual . Channel ): \"\"\"Filesystem Channel.\"\"\" supports_fanout = True def get_table ( self , exchange ): file = self . control_folder / f \" { exchange } .exchange\" try : f_obj = file . open ( \"r\" ) try : lock ( f_obj , LOCK_SH ) exchange_table = loads ( bytes_to_str ( f_obj . read ())) return [ exchange_queue_t ( * q ) for q in exchange_table ] finally : unlock ( f_obj ) f_obj . close () except FileNotFoundError : return [] except OSError : raise ChannelError ( f \"Cannot open { file } \" ) def _queue_bind ( self , exchange , routing_key , pattern , queue ): file = self . control_folder / f \" { exchange } .exchange\" self . control_folder . mkdir ( exist_ok = True ) queue_val = exchange_queue_t ( routing_key or \"\" , pattern or \"\" , queue or \"\" ) try : if file . exists (): f_obj = file . open ( \"rb+\" , buffering = 0 ) lock ( f_obj , LOCK_EX ) exchange_table = loads ( bytes_to_str ( f_obj . read ())) queues = [ exchange_queue_t ( * q ) for q in exchange_table ] if queue_val not in queues : queues . insert ( 0 , queue_val ) f_obj . seek ( 0 ) f_obj . write ( str_to_bytes ( dumps ( queues ))) else : f_obj = file . open ( \"wb\" , buffering = 0 ) lock ( f_obj , LOCK_EX ) queues = [ queue_val ] f_obj . write ( str_to_bytes ( dumps ( queues ))) finally : unlock ( f_obj ) f_obj . close () def _put_fanout ( self , exchange , payload , routing_key , ** kwargs ): for q in self . get_table ( exchange ): self . _put ( q . queue , payload , ** kwargs ) def _put ( self , queue , payload , ** kwargs ): \"\"\"Put `message` onto `queue`.\"\"\" filename = \" {} _ {} . {} .msg\" . format ( int ( round ( monotonic () * 1000 )), uuid . uuid4 (), queue ) filename = os . path . join ( self . data_folder_out , filename ) try : f = open ( filename , \"wb\" , buffering = 0 ) lock ( f , LOCK_EX ) f . write ( str_to_bytes ( dumps ( payload ))) except OSError : raise ChannelError ( f \"Cannot add file { filename !r} to directory\" ) finally : unlock ( f ) f . close () def _get ( self , queue ): \"\"\"Get next message from `queue`.\"\"\" queue_find = \".\" + queue + \".msg\" folder = os . listdir ( self . data_folder_in ) folder = sorted ( folder ) while len ( folder ) > 0 : filename = folder . pop ( 0 ) # only handle message for the requested queue if filename . find ( queue_find ) < 0 : continue if self . store_processed : processed_folder = self . processed_folder else : processed_folder = tempfile . gettempdir () try : # move the file to the tmp/processed folder shutil . move ( os . path . join ( self . data_folder_in , filename ), processed_folder , ) except OSError : # file could be locked, or removed in meantime so ignore continue filename = os . path . join ( processed_folder , filename ) try : f = open ( filename , \"rb\" ) payload = f . read () f . close () if not self . store_processed : os . remove ( filename ) except OSError : raise ChannelError ( f \"Cannot read file { filename !r} from queue.\" ) return loads ( bytes_to_str ( payload )) raise Empty () def _purge ( self , queue ): \"\"\"Remove all messages from `queue`.\"\"\" count = 0 queue_find = \".\" + queue + \".msg\" folder = os . listdir ( self . data_folder_in ) while len ( folder ) > 0 : filename = folder . pop () try : # only purge messages for the requested queue if filename . find ( queue_find ) < 0 : continue filename = os . path . join ( self . data_folder_in , filename ) os . remove ( filename ) count += 1 except OSError : # we simply ignore its existence, as it was probably # processed by another worker pass return count def _size ( self , queue ): \"\"\"Return the number of messages in `queue` as an :class:`int`.\"\"\" count = 0 queue_find = f \". { queue } .msg\" folder = os . listdir ( self . data_folder_in ) while len ( folder ) > 0 : filename = folder . pop () # only handle message for the requested queue if filename . find ( queue_find ) < 0 : continue count += 1 return count @property def transport_options ( self ): return self . connection . client . transport_options @cached_property def data_folder_in ( self ): return self . transport_options . get ( \"data_folder_in\" , \"data_in\" ) @cached_property def data_folder_out ( self ): return self . transport_options . get ( \"data_folder_out\" , \"data_out\" ) @cached_property def store_processed ( self ): return self . transport_options . get ( \"store_processed\" , False ) @cached_property def processed_folder ( self ): return self . transport_options . get ( \"processed_folder\" , \"processed\" ) @property def control_folder ( self ): return Path ( self . transport_options . get ( \"control_folder\" , \"control\" )) lock ( file , flags ) Create file lock. Source code in dvc_task/contrib/kombu_filesystem.py 49 50 51 def lock ( file , flags ): \"\"\"Create file lock.\"\"\" fcntl . flock ( file . fileno (), flags ) unlock ( file ) Remove file lock. Source code in dvc_task/contrib/kombu_filesystem.py 53 54 55 def unlock ( file ): \"\"\"Remove file lock.\"\"\" fcntl . flock ( file . fileno (), fcntl . LOCK_UN )","title":"Kombu filesystem"},{"location":"reference/dvc_task/contrib/kombu_filesystem/#dvc_task.contrib.kombu_filesystem.FilesystemChannel","text":"Bases: virtual . Channel Filesystem Channel. Source code in dvc_task/contrib/kombu_filesystem.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 class FilesystemChannel ( virtual . Channel ): \"\"\"Filesystem Channel.\"\"\" supports_fanout = True def get_table ( self , exchange ): file = self . control_folder / f \" { exchange } .exchange\" try : f_obj = file . open ( \"r\" ) try : lock ( f_obj , LOCK_SH ) exchange_table = loads ( bytes_to_str ( f_obj . read ())) return [ exchange_queue_t ( * q ) for q in exchange_table ] finally : unlock ( f_obj ) f_obj . close () except FileNotFoundError : return [] except OSError : raise ChannelError ( f \"Cannot open { file } \" ) def _queue_bind ( self , exchange , routing_key , pattern , queue ): file = self . control_folder / f \" { exchange } .exchange\" self . control_folder . mkdir ( exist_ok = True ) queue_val = exchange_queue_t ( routing_key or \"\" , pattern or \"\" , queue or \"\" ) try : if file . exists (): f_obj = file . open ( \"rb+\" , buffering = 0 ) lock ( f_obj , LOCK_EX ) exchange_table = loads ( bytes_to_str ( f_obj . read ())) queues = [ exchange_queue_t ( * q ) for q in exchange_table ] if queue_val not in queues : queues . insert ( 0 , queue_val ) f_obj . seek ( 0 ) f_obj . write ( str_to_bytes ( dumps ( queues ))) else : f_obj = file . open ( \"wb\" , buffering = 0 ) lock ( f_obj , LOCK_EX ) queues = [ queue_val ] f_obj . write ( str_to_bytes ( dumps ( queues ))) finally : unlock ( f_obj ) f_obj . close () def _put_fanout ( self , exchange , payload , routing_key , ** kwargs ): for q in self . get_table ( exchange ): self . _put ( q . queue , payload , ** kwargs ) def _put ( self , queue , payload , ** kwargs ): \"\"\"Put `message` onto `queue`.\"\"\" filename = \" {} _ {} . {} .msg\" . format ( int ( round ( monotonic () * 1000 )), uuid . uuid4 (), queue ) filename = os . path . join ( self . data_folder_out , filename ) try : f = open ( filename , \"wb\" , buffering = 0 ) lock ( f , LOCK_EX ) f . write ( str_to_bytes ( dumps ( payload ))) except OSError : raise ChannelError ( f \"Cannot add file { filename !r} to directory\" ) finally : unlock ( f ) f . close () def _get ( self , queue ): \"\"\"Get next message from `queue`.\"\"\" queue_find = \".\" + queue + \".msg\" folder = os . listdir ( self . data_folder_in ) folder = sorted ( folder ) while len ( folder ) > 0 : filename = folder . pop ( 0 ) # only handle message for the requested queue if filename . find ( queue_find ) < 0 : continue if self . store_processed : processed_folder = self . processed_folder else : processed_folder = tempfile . gettempdir () try : # move the file to the tmp/processed folder shutil . move ( os . path . join ( self . data_folder_in , filename ), processed_folder , ) except OSError : # file could be locked, or removed in meantime so ignore continue filename = os . path . join ( processed_folder , filename ) try : f = open ( filename , \"rb\" ) payload = f . read () f . close () if not self . store_processed : os . remove ( filename ) except OSError : raise ChannelError ( f \"Cannot read file { filename !r} from queue.\" ) return loads ( bytes_to_str ( payload )) raise Empty () def _purge ( self , queue ): \"\"\"Remove all messages from `queue`.\"\"\" count = 0 queue_find = \".\" + queue + \".msg\" folder = os . listdir ( self . data_folder_in ) while len ( folder ) > 0 : filename = folder . pop () try : # only purge messages for the requested queue if filename . find ( queue_find ) < 0 : continue filename = os . path . join ( self . data_folder_in , filename ) os . remove ( filename ) count += 1 except OSError : # we simply ignore its existence, as it was probably # processed by another worker pass return count def _size ( self , queue ): \"\"\"Return the number of messages in `queue` as an :class:`int`.\"\"\" count = 0 queue_find = f \". { queue } .msg\" folder = os . listdir ( self . data_folder_in ) while len ( folder ) > 0 : filename = folder . pop () # only handle message for the requested queue if filename . find ( queue_find ) < 0 : continue count += 1 return count @property def transport_options ( self ): return self . connection . client . transport_options @cached_property def data_folder_in ( self ): return self . transport_options . get ( \"data_folder_in\" , \"data_in\" ) @cached_property def data_folder_out ( self ): return self . transport_options . get ( \"data_folder_out\" , \"data_out\" ) @cached_property def store_processed ( self ): return self . transport_options . get ( \"store_processed\" , False ) @cached_property def processed_folder ( self ): return self . transport_options . get ( \"processed_folder\" , \"processed\" ) @property def control_folder ( self ): return Path ( self . transport_options . get ( \"control_folder\" , \"control\" ))","title":"FilesystemChannel"},{"location":"reference/dvc_task/contrib/kombu_filesystem/#dvc_task.contrib.kombu_filesystem.lock","text":"Create file lock. Source code in dvc_task/contrib/kombu_filesystem.py 49 50 51 def lock ( file , flags ): \"\"\"Create file lock.\"\"\" fcntl . flock ( file . fileno (), flags )","title":"lock()"},{"location":"reference/dvc_task/contrib/kombu_filesystem/#dvc_task.contrib.kombu_filesystem.unlock","text":"Remove file lock. Source code in dvc_task/contrib/kombu_filesystem.py 53 54 55 def unlock ( file ): \"\"\"Remove file lock.\"\"\" fcntl . flock ( file . fileno (), fcntl . LOCK_UN )","title":"unlock()"},{"location":"reference/dvc_task/proc/","text":"Process management module. ManagedProcess Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in dvc_task/proc/process.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass info : ProcessInfo property Return process information. pid : int property Return process PID. Raises: Type Description ValueError Process is not running. __init__ ( args , env = None , wdir = None , name = None ) Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in dvc_task/proc/process.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None info_path () Return process information file path. Source code in dvc_task/proc/process.py 118 119 120 121 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) pidfile_path () Return process pidfile path. Source code in dvc_task/proc/process.py 123 124 125 126 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) run () Run this process. Source code in dvc_task/proc/process.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise spawn ( args , kwargs ) classmethod Spawn a ManagedProcess command in the background. Source code in dvc_task/proc/process.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid stdout_path () Return redirected stdout path. Source code in dvc_task/proc/process.py 113 114 115 116 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) wait ( timeout = None ) Block until a process started with run has completed. Source code in dvc_task/proc/process.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode ProcessInfo dataclass Process information. Source code in dvc_task/proc/process.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename ) asdict () Return this info as a dictionary. Source code in dvc_task/proc/process.py 43 44 45 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) dump ( filename ) Dump the process information into a file. Source code in dvc_task/proc/process.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename ) from_dict ( data ) classmethod Construct ProcessInfo from the specified dictionary. Source code in dvc_task/proc/process.py 32 33 34 35 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) load ( filename ) classmethod Construct the process information from a file. Source code in dvc_task/proc/process.py 37 38 39 40 41 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) ProcessManager Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return yield from os . listdir ( self . wdir ) @reraise ( FileNotFoundError , KeyError ) def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) return ProcessInfo . load ( info_path ) @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group ) def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) __init__ ( wdir = None ) Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir cleanup ( force = False ) Remove stale (terminated) processes from this manager. Source code in dvc_task/proc/manager.py 194 195 196 197 198 199 200 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue follow ( name , encoding = None , sleep_interval = 1 ) Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in dvc_task/proc/manager.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) get ( key , default = None ) Return the specified process. Source code in dvc_task/proc/manager.py 65 66 67 68 69 70 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default interrupt ( name , group = True ) Send interrupt signal to specified named process Source code in dvc_task/proc/manager.py 152 153 154 155 156 157 158 159 def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) kill ( name , group = False ) Kill the specified named process. Source code in dvc_task/proc/manager.py 165 166 167 168 169 170 def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member processes () Iterate over managed processes. Source code in dvc_task/proc/manager.py 72 73 74 75 76 77 78 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue remove ( name , force = False ) Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in dvc_task/proc/manager.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] run_signature ( args , name = None , task = None , env = None , immutable = False ) Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in dvc_task/proc/manager.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) send_signal ( name , sig , group = False ) Send signal to the specified named process. Source code in dvc_task/proc/manager.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError terminate ( name , group = False ) Terminate the specified named process. Source code in dvc_task/proc/manager.py 161 162 163 def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group )","title":"Proc"},{"location":"reference/dvc_task/proc/#dvc_task.proc.ManagedProcess","text":"Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in dvc_task/proc/process.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass","title":"ManagedProcess"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.info","text":"Return process information.","title":"info"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.pid","text":"Return process PID. Raises: Type Description ValueError Process is not running.","title":"pid"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.__init__","text":"Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in dvc_task/proc/process.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None","title":"__init__()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.info_path","text":"Return process information file path. Source code in dvc_task/proc/process.py 118 119 120 121 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" )","title":"info_path()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.pidfile_path","text":"Return process pidfile path. Source code in dvc_task/proc/process.py 123 124 125 126 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" )","title":"pidfile_path()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.run","text":"Run this process. Source code in dvc_task/proc/process.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise","title":"run()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.spawn","text":"Spawn a ManagedProcess command in the background. Source code in dvc_task/proc/process.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid","title":"spawn()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.stdout_path","text":"Return redirected stdout path. Source code in dvc_task/proc/process.py 113 114 115 116 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" )","title":"stdout_path()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ManagedProcess.wait","text":"Block until a process started with run has completed. Source code in dvc_task/proc/process.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode","title":"wait()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.ProcessInfo","text":"Process information. Source code in dvc_task/proc/process.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename )","title":"ProcessInfo"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.asdict","text":"Return this info as a dictionary. Source code in dvc_task/proc/process.py 43 44 45 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self )","title":"asdict()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.dump","text":"Dump the process information into a file. Source code in dvc_task/proc/process.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename )","title":"dump()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.from_dict","text":"Construct ProcessInfo from the specified dictionary. Source code in dvc_task/proc/process.py 32 33 34 35 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data )","title":"from_dict()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.process.ProcessInfo.load","text":"Construct the process information from a file. Source code in dvc_task/proc/process.py 37 38 39 40 41 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj ))","title":"load()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.ProcessManager","text":"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return yield from os . listdir ( self . wdir ) @reraise ( FileNotFoundError , KeyError ) def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) return ProcessInfo . load ( info_path ) @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group ) def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"ProcessManager"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.__init__","text":"Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir","title":"__init__()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.cleanup","text":"Remove stale (terminated) processes from this manager. Source code in dvc_task/proc/manager.py 194 195 196 197 198 199 200 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue","title":"cleanup()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.follow","text":"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in dvc_task/proc/manager.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"follow()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.get","text":"Return the specified process. Source code in dvc_task/proc/manager.py 65 66 67 68 69 70 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default","title":"get()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.interrupt","text":"Send interrupt signal to specified named process Source code in dvc_task/proc/manager.py 152 153 154 155 156 157 158 159 def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group )","title":"interrupt()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.kill","text":"Kill the specified named process. Source code in dvc_task/proc/manager.py 165 166 167 168 169 170 def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member","title":"kill()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.processes","text":"Iterate over managed processes. Source code in dvc_task/proc/manager.py 72 73 74 75 76 77 78 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue","title":"processes()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.remove","text":"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in dvc_task/proc/manager.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ]","title":"remove()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.run_signature","text":"Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in dvc_task/proc/manager.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , )","title":"run_signature()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.send_signal","text":"Send signal to the specified named process. Source code in dvc_task/proc/manager.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError","title":"send_signal()"},{"location":"reference/dvc_task/proc/#dvc_task.proc.manager.ProcessManager.terminate","text":"Terminate the specified named process. Source code in dvc_task/proc/manager.py 161 162 163 def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group )","title":"terminate()"},{"location":"reference/dvc_task/proc/exceptions/","text":"Process exceptions. ProcessNotFoundError Bases: DvcTaskError Process does not exist. Source code in dvc_task/proc/exceptions.py 12 13 14 15 16 class ProcessNotFoundError ( DvcTaskError ): \"\"\"Process does not exist.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' does not exist.\" ) ProcessNotTerminatedError Bases: DvcTaskError Process is still running. Source code in dvc_task/proc/exceptions.py 5 6 7 8 9 class ProcessNotTerminatedError ( DvcTaskError ): \"\"\"Process is still running.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' has not been terminated.\" ) TimeoutExpired Bases: DvcTaskError Process timeout expired. Source code in dvc_task/proc/exceptions.py 19 20 21 22 23 24 25 class TimeoutExpired ( DvcTaskError ): \"\"\"Process timeout expired.\"\"\" def __init__ ( self , cmd , timeout ): super () . __init__ ( f \"' { cmd } ' did not complete before timeout ' { timeout } '\" ) self . cmd = cmd self . timeout = timeout UnsupportedSignalError Bases: DvcTaskError Unsupported process signal. Source code in dvc_task/proc/exceptions.py 28 29 30 31 32 class UnsupportedSignalError ( DvcTaskError ): \"\"\"Unsupported process signal.\"\"\" def __init__ ( self , sig ): super () . __init__ ( f \"Unsupported signal: { sig } \" )","title":"Exceptions"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.ProcessNotFoundError","text":"Bases: DvcTaskError Process does not exist. Source code in dvc_task/proc/exceptions.py 12 13 14 15 16 class ProcessNotFoundError ( DvcTaskError ): \"\"\"Process does not exist.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' does not exist.\" )","title":"ProcessNotFoundError"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.ProcessNotTerminatedError","text":"Bases: DvcTaskError Process is still running. Source code in dvc_task/proc/exceptions.py 5 6 7 8 9 class ProcessNotTerminatedError ( DvcTaskError ): \"\"\"Process is still running.\"\"\" def __init__ ( self , name ): super () . __init__ ( f \"Managed process ' { name } ' has not been terminated.\" )","title":"ProcessNotTerminatedError"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.TimeoutExpired","text":"Bases: DvcTaskError Process timeout expired. Source code in dvc_task/proc/exceptions.py 19 20 21 22 23 24 25 class TimeoutExpired ( DvcTaskError ): \"\"\"Process timeout expired.\"\"\" def __init__ ( self , cmd , timeout ): super () . __init__ ( f \"' { cmd } ' did not complete before timeout ' { timeout } '\" ) self . cmd = cmd self . timeout = timeout","title":"TimeoutExpired"},{"location":"reference/dvc_task/proc/exceptions/#dvc_task.proc.exceptions.UnsupportedSignalError","text":"Bases: DvcTaskError Unsupported process signal. Source code in dvc_task/proc/exceptions.py 28 29 30 31 32 class UnsupportedSignalError ( DvcTaskError ): \"\"\"Unsupported process signal.\"\"\" def __init__ ( self , sig ): super () . __init__ ( f \"Unsupported signal: { sig } \" )","title":"UnsupportedSignalError"},{"location":"reference/dvc_task/proc/manager/","text":"Serverless process manager. ProcessManager Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return yield from os . listdir ( self . wdir ) @reraise ( FileNotFoundError , KeyError ) def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) return ProcessInfo . load ( info_path ) @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group ) def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) __init__ ( wdir = None ) Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir cleanup ( force = False ) Remove stale (terminated) processes from this manager. Source code in dvc_task/proc/manager.py 194 195 196 197 198 199 200 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue follow ( name , encoding = None , sleep_interval = 1 ) Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in dvc_task/proc/manager.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset ) get ( key , default = None ) Return the specified process. Source code in dvc_task/proc/manager.py 65 66 67 68 69 70 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default interrupt ( name , group = True ) Send interrupt signal to specified named process Source code in dvc_task/proc/manager.py 152 153 154 155 156 157 158 159 def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) kill ( name , group = False ) Kill the specified named process. Source code in dvc_task/proc/manager.py 165 166 167 168 169 170 def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member processes () Iterate over managed processes. Source code in dvc_task/proc/manager.py 72 73 74 75 76 77 78 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue remove ( name , force = False ) Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in dvc_task/proc/manager.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] run_signature ( args , name = None , task = None , env = None , immutable = False ) Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in dvc_task/proc/manager.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) send_signal ( name , sig , group = False ) Send signal to the specified named process. Source code in dvc_task/proc/manager.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError terminate ( name , group = False ) Terminate the specified named process. Source code in dvc_task/proc/manager.py 161 162 163 def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group )","title":"Manager"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager","text":"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. Source code in dvc_task/proc/manager.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 class ProcessManager : \"\"\"Manager for controlling background ManagedProcess(es) via celery. Spawned process entries are kept in the manager directory until they are explicitly removed (with remove() or cleanup()) so that return value and log information can be accessed after a process has completed. \"\"\" def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir def __iter__ ( self ) -> Generator [ str , None , None ]: if not os . path . exists ( self . wdir ): return yield from os . listdir ( self . wdir ) @reraise ( FileNotFoundError , KeyError ) def __getitem__ ( self , key : str ) -> \"ProcessInfo\" : info_path = self . _get_info_path ( key ) return ProcessInfo . load ( info_path ) @reraise ( FileNotFoundError , KeyError ) def __setitem__ ( self , key : str , value : \"ProcessInfo\" ): info_path = self . _get_info_path ( key ) value . dump ( info_path ) def __delitem__ ( self , key : str ) -> None : path = os . path . join ( self . wdir , key ) if os . path . exists ( path ): remove ( path ) def _get_info_path ( self , key : str ) -> str : return os . path . join ( self . wdir , key , f \" { key } .json\" ) def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , ) def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group ) def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group ) def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ] def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"ProcessManager"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.__init__","text":"Construct a ProcessManager Parameters: Name Type Description Default wdir Optional [ str ] Directory used for storing process information. Defaults to the current working directory. None Source code in dvc_task/proc/manager.py 30 31 32 33 34 35 36 37 38 39 40 def __init__ ( self , wdir : Optional [ str ] = None , ): \"\"\"Construct a ProcessManager Arguments: wdir: Directory used for storing process information. Defaults to the current working directory. \"\"\" self . wdir = wdir or os . curdir","title":"__init__()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.cleanup","text":"Remove stale (terminated) processes from this manager. Source code in dvc_task/proc/manager.py 194 195 196 197 198 199 200 def cleanup ( self , force : bool = False ): \"\"\"Remove stale (terminated) processes from this manager.\"\"\" for name in self : try : self . remove ( name , force ) except ProcessNotTerminatedError : continue","title":"cleanup()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.follow","text":"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Parameters: Name Type Description Default name str Process name. required encoding Optional [ str ] Text encoding for redirected output. Defaults to locale.getpreferredencoding() . None sleep_interval int Sleep interval for follow iterations (when waiting for output). 1 Note Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). Source code in dvc_task/proc/manager.py 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 def follow ( self , name : str , encoding : Optional [ str ] = None , sleep_interval : int = 1 , ) -> Generator [ str , None , None ]: \"\"\"Iterate over lines in redirected output for a process. This will block calling thread when waiting for output (until the followed process has exited). Arguments: name: Process name. encoding: Text encoding for redirected output. Defaults to `locale.getpreferredencoding()`. sleep_interval: Sleep interval for follow iterations (when waiting for output). Note: Yielded strings may not always end in line terminators (all available output will yielded if EOF is reached). \"\"\" output_path = self [ name ] . stdout if output_path is None : return with open ( output_path , encoding = encoding or locale . getpreferredencoding (), ) as fobj : while True : offset = fobj . tell () line = fobj . readline () if line : yield line else : info = self [ name ] if info . returncode is not None : return time . sleep ( sleep_interval ) fobj . seek ( offset )","title":"follow()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.get","text":"Return the specified process. Source code in dvc_task/proc/manager.py 65 66 67 68 69 70 def get ( self , key : str , default = None ) -> \"ProcessInfo\" : \"\"\"Return the specified process.\"\"\" try : return self [ key ] except KeyError : return default","title":"get()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.interrupt","text":"Send interrupt signal to specified named process Source code in dvc_task/proc/manager.py 152 153 154 155 156 157 158 159 def interrupt ( self , name : str , group : bool = True ): \"\"\"Send interrupt signal to specified named process\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . CTRL_C_EVENT , group # pylint: disable=no-member ) else : self . send_signal ( name , signal . SIGINT , group )","title":"interrupt()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.kill","text":"Kill the specified named process. Source code in dvc_task/proc/manager.py 165 166 167 168 169 170 def kill ( self , name : str , group : bool = False ): \"\"\"Kill the specified named process.\"\"\" if sys . platform == \"win32\" : self . send_signal ( name , signal . SIGTERM , group ) else : self . send_signal ( name , signal . SIGKILL , group ) # pylint: disable=no-member","title":"kill()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.processes","text":"Iterate over managed processes. Source code in dvc_task/proc/manager.py 72 73 74 75 76 77 78 def processes ( self ) -> Generator [ Tuple [ str , \"ProcessInfo\" ], None , None ]: \"\"\"Iterate over managed processes.\"\"\" for name in self : try : yield name , self [ name ] except KeyError : continue","title":"processes()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.remove","text":"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if force is True`, otherwise an exception will be raised. Source code in dvc_task/proc/manager.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def remove ( self , name : str , force : bool = False ): \"\"\"Remove the specified named process from this manager. If the specified process is still running, it will be forcefully killed if `force` is True`, otherwise an exception will be raised. Raises: ProcessNotTerminatedError if the specified process is still running and was not forcefully killed. \"\"\" try : process_info = self [ name ] except KeyError : return if process_info . returncode is None and not force : raise ProcessNotTerminatedError ( name ) try : self . kill ( name ) except ProcessLookupError : pass del self [ name ]","title":"remove()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.run_signature","text":"Return signature for a task which runs a command in the background. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to run. required name Optional [ str ] Optional name to use for the spawned process. None task Optional [ str ] Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. None env Optional [ Dict [ str , str ]] Optional environment to be passed into the process. None immutable bool True if the returned Signature should be immutable. False Returns: Type Description Signature Celery signature for the run task. Source code in dvc_task/proc/manager.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def run_signature ( self , args : Union [ str , List [ str ]], name : Optional [ str ] = None , task : Optional [ str ] = None , env : Optional [ Dict [ str , str ]] = None , immutable : bool = False , ) -> Signature : \"\"\"Return signature for a task which runs a command in the background. Arguments: args: Command to run. name: Optional name to use for the spawned process. task: Optional name of Celery task to use for spawning the process. Defaults to 'dvc_task.proc.tasks.run'. env: Optional environment to be passed into the process. immutable: True if the returned Signature should be immutable. Returns: Celery signature for the run task. \"\"\" name = name or uuid () task = task or \"dvc_task.proc.tasks.run\" return signature ( task , args = ( args ,), kwargs = { \"name\" : name , \"wdir\" : os . path . join ( self . wdir , name ), \"env\" : env , }, immutable = immutable , )","title":"run_signature()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.send_signal","text":"Send signal to the specified named process. Source code in dvc_task/proc/manager.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def send_signal ( self , name : str , sig : int , group : bool = False ): \"\"\"Send `signal` to the specified named process.\"\"\" try : process_info = self [ name ] except KeyError as exc : raise ProcessLookupError from exc if sys . platform == \"win32\" : if sig not in ( signal . SIGTERM , signal . CTRL_C_EVENT , signal . CTRL_BREAK_EVENT , ): raise UnsupportedSignalError ( sig ) def handle_closed_process (): logging . warning ( \"Process ' %s ' had already aborted unexpectedly.\" , name ) process_info . returncode = - 1 self [ name ] = process_info if process_info . returncode is None : try : if sys . platform != \"win32\" and group : pgid = os . getpgid ( process_info . pid ) # pylint: disable=no-member os . killpg ( pgid , sig ) # pylint: disable=no-member else : os . kill ( process_info . pid , sig ) except ProcessLookupError : handle_closed_process () raise except OSError as exc : if sys . platform == \"win32\" : if exc . winerror == 87 : handle_closed_process () raise ProcessLookupError from exc raise else : raise ProcessLookupError","title":"send_signal()"},{"location":"reference/dvc_task/proc/manager/#dvc_task.proc.manager.ProcessManager.terminate","text":"Terminate the specified named process. Source code in dvc_task/proc/manager.py 161 162 163 def terminate ( self , name : str , group : bool = False ): \"\"\"Terminate the specified named process.\"\"\" self . send_signal ( name , signal . SIGTERM , group )","title":"terminate()"},{"location":"reference/dvc_task/proc/process/","text":"Managed process module. ManagedProcess Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in dvc_task/proc/process.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass info : ProcessInfo property Return process information. pid : int property Return process PID. Raises: Type Description ValueError Process is not running. __init__ ( args , env = None , wdir = None , name = None ) Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in dvc_task/proc/process.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None info_path () Return process information file path. Source code in dvc_task/proc/process.py 118 119 120 121 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) pidfile_path () Return process pidfile path. Source code in dvc_task/proc/process.py 123 124 125 126 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) run () Run this process. Source code in dvc_task/proc/process.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise spawn ( args , kwargs ) classmethod Spawn a ManagedProcess command in the background. Source code in dvc_task/proc/process.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid stdout_path () Return redirected stdout path. Source code in dvc_task/proc/process.py 113 114 115 116 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) wait ( timeout = None ) Block until a process started with run has completed. Source code in dvc_task/proc/process.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode ProcessInfo dataclass Process information. Source code in dvc_task/proc/process.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename ) asdict () Return this info as a dictionary. Source code in dvc_task/proc/process.py 43 44 45 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) dump ( filename ) Dump the process information into a file. Source code in dvc_task/proc/process.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename ) from_dict ( data ) classmethod Construct ProcessInfo from the specified dictionary. Source code in dvc_task/proc/process.py 32 33 34 35 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) load ( filename ) classmethod Construct the process information from a file. Source code in dvc_task/proc/process.py 37 38 39 40 41 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj ))","title":"Process"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess","text":"Bases: AbstractContextManager Class to manage the specified process with redirected output. stdout and stderr will both be redirected to .out. Interactive processes (requiring stdin input) are currently unsupported. Source code in dvc_task/proc/process.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 class ManagedProcess ( AbstractContextManager ): \"\"\"Class to manage the specified process with redirected output. stdout and stderr will both be redirected to <name>.out. Interactive processes (requiring stdin input) are currently unsupported. \"\"\" def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None def __enter__ ( self ): if self . _proc is None : self . run () return self def __exit__ ( self , * args , ** kwargs ): self . wait () def _close_fds ( self ): with self . _fd_stack : pass def _make_path ( self , path : str ) -> str : return os . path . join ( self . wdir , path ) if self . wdir else path @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" ) @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" ) @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" ) @property def info ( self ) -> \"ProcessInfo\" : \"\"\"Return process information.\"\"\" return ProcessInfo ( pid = self . pid , stdin = None , stdout = self . stdout_path , stderr = None , returncode = self . returncode , ) @property def pid ( self ) -> int : \"\"\"Return process PID. Raises: ValueError: Process is not running. \"\"\" if self . _proc is None : raise ValueError return self . _proc . pid def _make_wdir ( self ): if self . wdir : makedirs ( self . wdir , exist_ok = True ) def _dump ( self ): self . _make_wdir () self . info . dump ( self . info_path ) with open ( self . pidfile_path , \"w\" , encoding = \"utf-8\" ) as fobj : fobj . write ( str ( self . pid )) def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid @classmethod def _spawn ( cls , * args , ** kwargs ): with cls ( * args , ** kwargs ): pass","title":"ManagedProcess"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.info","text":"Return process information.","title":"info"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.pid","text":"Return process PID. Raises: Type Description ValueError Process is not running.","title":"pid"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.__init__","text":"Construct a MangedProcess. Parameters: Name Type Description Default args Union [ str , List [ str ]] Command to be run. required env Optional [ Dict [ str , str ]] Optional environment variables. None wdir Optional [ str ] If specified, redirected output files will be placed in wdir . Defaults to current working directory. None name Optional [ str ] Name to use for this process, if not specified a UUID will be generated instead. None Source code in dvc_task/proc/process.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def __init__ ( self , args : Union [ str , List [ str ]], env : Optional [ Dict [ str , str ]] = None , wdir : Optional [ str ] = None , name : Optional [ str ] = None , ): \"\"\"Construct a MangedProcess. Arguments: args: Command to be run. env: Optional environment variables. wdir: If specified, redirected output files will be placed in `wdir`. Defaults to current working directory. name: Name to use for this process, if not specified a UUID will be generated instead. \"\"\" self . args : List [ str ] = ( shlex . split ( args , posix = os . name == \"posix\" ) if isinstance ( args , str ) else list ( args ) ) self . env = env self . wdir = wdir self . name = name or uuid () self . returncode : Optional [ int ] = None self . _fd_stack = ExitStack () self . _proc : Optional [ subprocess . Popen ] = None","title":"__init__()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.info_path","text":"Return process information file path. Source code in dvc_task/proc/process.py 118 119 120 121 @cached_property def info_path ( self ) -> str : \"\"\"Return process information file path.\"\"\" return self . _make_path ( f \" { self . name } .json\" )","title":"info_path()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.pidfile_path","text":"Return process pidfile path. Source code in dvc_task/proc/process.py 123 124 125 126 @cached_property def pidfile_path ( self ) -> str : \"\"\"Return process pidfile path.\"\"\" return self . _make_path ( f \" { self . name } .pid\" )","title":"pidfile_path()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.run","text":"Run this process. Source code in dvc_task/proc/process.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def run ( self ): \"\"\"Run this process.\"\"\" self . _make_wdir () logger . debug ( \"Appending output to ' %s '\" , self . stdout_path , ) stdout = self . _fd_stack . enter_context ( open ( self . stdout_path , \"ab\" )) try : # pylint: disable=consider-using-with self . _proc = subprocess . Popen ( # nosec B603 self . args , stdin = subprocess . DEVNULL , stdout = stdout , stderr = subprocess . STDOUT , close_fds = True , shell = False , env = self . env , ) self . _dump () except Exception : if self . _proc is not None : self . _proc . kill () self . _close_fds () raise","title":"run()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.spawn","text":"Spawn a ManagedProcess command in the background. Source code in dvc_task/proc/process.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 @classmethod def spawn ( cls , * args , ** kwargs ) -> Optional [ int ]: \"\"\"Spawn a ManagedProcess command in the background. Returns: The spawned process PID. \"\"\" proc = _DaemonProcess ( target = cls . _spawn , args = args , kwargs = kwargs , daemon = True , ) proc . start () # Do not terminate the child daemon when the main process exits # pylint: disable=protected-access mp . process . _children . discard ( proc ) # type: ignore[attr-defined] return proc . pid","title":"spawn()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.stdout_path","text":"Return redirected stdout path. Source code in dvc_task/proc/process.py 113 114 115 116 @cached_property def stdout_path ( self ) -> str : \"\"\"Return redirected stdout path.\"\"\" return self . _make_path ( f \" { self . name } .out\" )","title":"stdout_path()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ManagedProcess.wait","text":"Block until a process started with run has completed. Source code in dvc_task/proc/process.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def wait ( self , timeout : Optional [ int ] = None ) -> Optional [ int ]: \"\"\"Block until a process started with `run` has completed. Raises: TimeoutExpired if `timeout` was set and the process did not terminate after `timeout` seconds. \"\"\" if self . returncode is not None or self . _proc is None : return self . returncode try : self . _proc . wait ( timeout = timeout ) except subprocess . TimeoutExpired as exc : raise TimeoutExpired ( exc . cmd , exc . timeout ) from exc except KeyboardInterrupt : pass self . returncode = self . _proc . returncode self . _close_fds () self . _dump () return self . returncode","title":"wait()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo","text":"Process information. Source code in dvc_task/proc/process.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 @dataclass class ProcessInfo : \"\"\"Process information.\"\"\" pid : int stdin : Optional [ str ] stdout : Optional [ str ] stderr : Optional [ str ] returncode : Optional [ int ] @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data ) @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj )) def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self ) def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename )","title":"ProcessInfo"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.asdict","text":"Return this info as a dictionary. Source code in dvc_task/proc/process.py 43 44 45 def asdict ( self ) -> Dict [ str , Any ]: \"\"\"Return this info as a dictionary.\"\"\" return asdict ( self )","title":"asdict()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.dump","text":"Dump the process information into a file. Source code in dvc_task/proc/process.py 47 48 49 50 51 52 53 54 55 56 57 58 59 def dump ( self , filename : str ) -> None : \"\"\"Dump the process information into a file.\"\"\" directory , file = os . path . split ( filename ) with tempfile . NamedTemporaryFile ( mode = \"w\" , encoding = \"utf-8\" , dir = directory , prefix = f \" { file } .\" , suffix = \".tmp\" , delete = False , ) as tmp : json . dump ( self . asdict (), tmp ) os . replace ( tmp . name , filename )","title":"dump()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.from_dict","text":"Construct ProcessInfo from the specified dictionary. Source code in dvc_task/proc/process.py 32 33 34 35 @classmethod def from_dict ( cls , data : Dict [ str , Any ]) -> \"ProcessInfo\" : \"\"\"Construct ProcessInfo from the specified dictionary.\"\"\" return cls ( ** data )","title":"from_dict()"},{"location":"reference/dvc_task/proc/process/#dvc_task.proc.process.ProcessInfo.load","text":"Construct the process information from a file. Source code in dvc_task/proc/process.py 37 38 39 40 41 @classmethod def load ( cls , filename : str ) -> \"ProcessInfo\" : \"\"\"Construct the process information from a file.\"\"\" with open ( filename , encoding = \"utf-8\" ) as fobj : return cls . from_dict ( json . load ( fobj ))","title":"load()"},{"location":"reference/dvc_task/proc/tasks/","text":"Celery tasks. run ( self , args , kwargs ) Run a command inside a celery task. Accepts the same arguments as proc.process.ManagedProcess . Source code in dvc_task/proc/tasks.py 9 10 11 12 13 14 15 16 17 18 19 @shared_task ( bind = True ) def run ( # pylint: disable=unused-argument self , * args : Any , ** kwargs : Any ) -> Dict [ str , Any ]: \"\"\"Run a command inside a celery task. Accepts the same arguments as `proc.process.ManagedProcess`. \"\"\" with ManagedProcess ( * args , ** kwargs ) as proc : pass return proc . info . asdict ()","title":"Tasks"},{"location":"reference/dvc_task/proc/tasks/#dvc_task.proc.tasks.run","text":"Run a command inside a celery task. Accepts the same arguments as proc.process.ManagedProcess . Source code in dvc_task/proc/tasks.py 9 10 11 12 13 14 15 16 17 18 19 @shared_task ( bind = True ) def run ( # pylint: disable=unused-argument self , * args : Any , ** kwargs : Any ) -> Dict [ str , Any ]: \"\"\"Run a command inside a celery task. Accepts the same arguments as `proc.process.ManagedProcess`. \"\"\" with ManagedProcess ( * args , ** kwargs ) as proc : pass return proc . info . asdict ()","title":"run()"},{"location":"reference/dvc_task/worker/","text":"DVC Task worker factories. TemporaryWorker Temporary worker that automatically shuts down when queue is empty. Source code in dvc_task/worker/temporary.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,)) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" ) __init__ ( app , timeout = 60 , kwargs ) Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in dvc_task/worker/temporary.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs monitor ( name ) Monitor the worker and stop it when the queue is empty. Source code in dvc_task/worker/temporary.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" ) start ( name ) Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required Source code in dvc_task/worker/temporary.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,)) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv )","title":"Worker"},{"location":"reference/dvc_task/worker/#dvc_task.worker.TemporaryWorker","text":"Temporary worker that automatically shuts down when queue is empty. Source code in dvc_task/worker/temporary.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,)) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" )","title":"TemporaryWorker"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.__init__","text":"Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in dvc_task/worker/temporary.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs","title":"__init__()"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.monitor","text":"Monitor the worker and stop it when the queue is empty. Source code in dvc_task/worker/temporary.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" )","title":"monitor()"},{"location":"reference/dvc_task/worker/#dvc_task.worker.temporary.TemporaryWorker.start","text":"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required Source code in dvc_task/worker/temporary.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,)) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv )","title":"start()"},{"location":"reference/dvc_task/worker/temporary/","text":"Temporary worker module. TemporaryWorker Temporary worker that automatically shuts down when queue is empty. Source code in dvc_task/worker/temporary.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,)) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" ) __init__ ( app , timeout = 60 , kwargs ) Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in dvc_task/worker/temporary.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs monitor ( name ) Monitor the worker and stop it when the queue is empty. Source code in dvc_task/worker/temporary.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" ) start ( name ) Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required Source code in dvc_task/worker/temporary.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,)) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv )","title":"Temporary"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker","text":"Temporary worker that automatically shuts down when queue is empty. Source code in dvc_task/worker/temporary.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class TemporaryWorker : \"\"\"Temporary worker that automatically shuts down when queue is empty.\"\"\" def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,)) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv ) @staticmethod def _parse_config ( config : Mapping [ str , Any ]) -> List [ str ]: loglevel = config . get ( \"loglevel\" , \"info\" ) argv = [ f \"--loglevel= { loglevel } \" ] for key in ( \"hostname\" , \"pool\" , \"concurrency\" , \"prefetch_multiplier\" ): value = config . get ( key ) if value : argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } = { value } \" ) for key in ( \"without_heartbeat\" , \"without_mingle\" , \"without_gossip\" , ): if config . get ( key ): argv_key = key . replace ( \"_\" , \"-\" ) argv . append ( f \"-- { argv_key } \" ) if config . get ( \"task_events\" ): argv . append ( \"-E\" ) return argv def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" )","title":"TemporaryWorker"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.__init__","text":"Construct a worker. Parameters: Name Type Description Default app Celery Celery application instance. required timeout int Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. 60 Additional keyword arguments will be passed as celery worker configuration. Source code in dvc_task/worker/temporary.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def __init__ ( # pylint: disable=too-many-arguments self , app : Celery , timeout : int = 60 , ** kwargs , ): \"\"\"Construct a worker. Arguments: app: Celery application instance. timeout: Queue timeout in seconds. Worker will be terminated if the queue remains empty after timeout. Additional keyword arguments will be passed as celery worker configuration. \"\"\" self . app = app self . timeout = timeout self . config = kwargs","title":"__init__()"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.monitor","text":"Monitor the worker and stop it when the queue is empty. Source code in dvc_task/worker/temporary.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def monitor ( self , name : str ) -> None : \"\"\"Monitor the worker and stop it when the queue is empty.\"\"\" logger . debug ( \"monitor: waiting for worker to start\" ) nodename = default_nodename ( name ) while not self . app . control . ping ( destination = [ nodename ]): # wait for worker to start time . sleep ( 1 ) def _tasksets ( nodes ): for taskset in ( nodes . active (), nodes . scheduled (), nodes . reserved (), ): if taskset is not None : yield from taskset . values () if isinstance ( self . app , FSApp ): yield from self . app . iter_queued () logger . info ( \"monitor: watching celery worker ' %s '\" , nodename ) while self . app . control . ping ( destination = [ nodename ]): time . sleep ( self . timeout ) nodes = self . app . control . inspect ( # type: ignore[call-arg] destination = [ nodename ] ) if nodes is None or not any ( tasks for tasks in _tasksets ( nodes )): logger . info ( \"monitor: shutting down due to empty queue.\" ) self . app . control . shutdown ( destination = [ nodename ]) break logger . info ( \"monitor: done\" )","title":"monitor()"},{"location":"reference/dvc_task/worker/temporary/#dvc_task.worker.temporary.TemporaryWorker.start","text":"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Parameters: Name Type Description Default name str Celery worker name. required Source code in dvc_task/worker/temporary.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def start ( self , name : str ) -> None : \"\"\"Start the worker if it does not already exist. Runs the Celery worker main thread in the current process. Arguments: name: Celery worker name. \"\"\" if os . name == \"nt\" : # see https://github.com/celery/billiard/issues/247 os . environ [ \"FORKED_BY_MULTIPROCESSING\" ] = \"1\" if not self . app . control . ping ( destination = [ name ]): monitor = threading . Thread ( target = self . monitor , daemon = True , args = ( name ,)) monitor . start () config = dict ( self . config ) config [ \"hostname\" ] = name argv = [ \"worker\" ] argv . extend ( self . _parse_config ( config )) self . app . worker_main ( argv = argv )","title":"start()"}]}